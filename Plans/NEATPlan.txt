checklist:

eval_genomes(genomes, config):
	for genome_id, genome in genomes:
		genome.fitness = 0
		create network and append to net list
		create player and append to agentlist
		append genome to genome list - or make an agent class to hold all of this
	
	while len(agents) > 0:
		play one turn of the game
		you can get decision with net.activate((inputs tuples))
		update agent reward with genome.fitness += reward whenever it gets a reward
		if the game ends then you can pop the agent from that list
		if the game goes past a number of maximum number of times the agent has to play then break (illegal loop prevention)
		
run(config_file_path):
	get config from the path
	create population
	add reporters and statistics
	call winner = p.run(eval_genomes, numgens)
	print winner
----------------------------------------------------------------------------------------------------------------------------------------------
Agent: (genome)
	genome variable with fitness value preloaded
	network variable from genome
	
	play(state)
		net.activate(state)
		logic to return action from decision

	update_fitness(increment)
		genome += increment

----------------------------------------------------------------------------------------------------------------------------------------------
Gym: ()
	eval(genomes, config)
		will need a self.opponent1 and 2 set
		create list of agents for each genome in genomes (with genome fitness 0)
		while lenght of this list is more than 0
			play a turn and do the stuff above	

	simrun(config_file_path, opponent1, opponent2):
		do all the suff above set the opponents
	
	